{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanHongChen/GenAI-Tutor-Bootcamp-2025/blob/dev/Taigen_Paim0n_ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RAG**"
      ],
      "metadata": {
        "id": "UjHu99s_3f73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google.genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtU7ZQ-XOz2d",
        "outputId": "48893783-3bd1-4373-cc1f-272736d184ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google.genai in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google.genai) (2.27.0)\n",
            "Requirement already satisfied: pydantic<3.0.0dev,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google.genai) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google.genai) (2.32.3)\n",
            "Requirement already satisfied: websockets<15.0dev,>=13.0 in /usr/local/lib/python3.11/dist-packages (from google.genai) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google.genai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google.genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google.genai) (4.9)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google.genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google.genai) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0dev,>=2.0.0->google.genai) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google.genai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google.genai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google.genai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0dev,>=2.28.1->google.genai) (2025.1.31)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google.genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyAQepcLSlev8sEynOtagrUln56HMunod48\"\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)  # corp developer\n",
        "chat = client.chats.create(model=\"gemini-2.0-flash-001\")\n",
        "\n",
        "\n",
        "prompt = \"Testing prompt\"\n",
        "\n",
        "response_text = \"\"\n",
        "for chunk in chat.send_message_stream(prompt):\n",
        "    print(chunk.text, end=\"\")\n",
        "    response_text += chunk.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiSSo8pmOnPe",
        "outputId": "43feffbc-d488-44a1-ebe6-4cc4c54e1e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I'm ready to be tested! What would you like me to do? Please give me a task, a question, or a request. I'll do my best to respond appropriately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6rYSksiQl-4",
        "outputId": "cd2888ae-ee63-4b24-eb56-056e90925ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.15.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.30.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.67.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.30.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.51b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.28.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from typing import List\n",
        "from google.colab import userdata  # For Colab secrets\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download NLTK data (do this only once)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Load text data\n",
        "with open('wishing-info.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "def split_text(text):\n",
        "    \"\"\"\n",
        "    Split the input text into meaningful chunks (sentences).\n",
        "    Returns a list of text chunks.\n",
        "    \"\"\"\n",
        "    chunks = sent_tokenize(text)\n",
        "    return chunks\n",
        "\n",
        "chunked_text = split_text(text)\n",
        "print(f\"Number of chunks: {len(chunked_text)}\") # Debug: Check chunking\n",
        "\n",
        "# --- ChromaDB Setup ---\n",
        "\n",
        "db_folder = \"chroma_db\"\n",
        "db_name = \"rag_experiment\"\n",
        "db_path = os.path.join(os.getcwd(), db_folder)\n",
        "print(f\"DB Path: {db_path}\")  # Debug: Check path\n",
        "\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "        if not gemini_api_key:\n",
        "            raise ValueError(\"Gemini API Key not provided.\")\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        model = \"models/embedding-001\"\n",
        "        title = \"Custom query\"\n",
        "        try:  # Added error handling\n",
        "            response = genai.embed_content(model=model, content=input, task_type=\"retrieval_document\", title=title)\n",
        "            return response[\"embedding\"]\n",
        "        except Exception as e:\n",
        "            print(f\"Error during embedding: {e}\")\n",
        "            return [] # Return empty embeddings to avoid crashing\n",
        "        # embeddings = []\n",
        "        # for doc in input:\n",
        "        #     try:\n",
        "        #         response = genai.embed_content(model=model, content=doc, task_type=\"retrieval_document\", title=title)\n",
        "        #         embeddings.append(response['embedding'])\n",
        "        #     except Exception as e:\n",
        "        #         print(f\"Error during embedding of document: {doc}\\nError: {e}\")\n",
        "        #         embeddings.append([])  # Add an empty list to maintain index alignment\n",
        "        # return embeddings\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "import google.generativeai as genai\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from typing import List\n",
        "from google.colab import userdata  # For Colab secrets\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download NLTK data (do this only once)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "# Load text data\n",
        "with open('wishing-info.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "def split_text(text):\n",
        "    \"\"\"\n",
        "    Split the input text into meaningful chunks (sentences).\n",
        "    Returns a list of text chunks.\n",
        "    \"\"\"\n",
        "    chunks = sent_tokenize(text)\n",
        "    return chunks\n",
        "\n",
        "chunked_text = split_text(text)\n",
        "print(f\"Number of chunks: {len(chunked_text)}\") # Debug: Check chunking\n",
        "\n",
        "# --- ChromaDB Setup ---\n",
        "\n",
        "db_folder = \"chroma_db\"\n",
        "db_name = \"rag_experiment\"\n",
        "db_path = os.path.join(os.getcwd(), db_folder)\n",
        "print(f\"DB Path: {db_path}\")  # Debug: Check path\n",
        "\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "        if not gemini_api_key:\n",
        "            raise ValueError(\"Gemini API Key not provided.\")\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        model = \"models/embedding-001\"\n",
        "        title = \"Custom query\"\n",
        "\n",
        "        embeddings = []\n",
        "        for doc in input:\n",
        "            try:\n",
        "                response = genai.embed_content(model=model, content=doc, task_type=\"retrieval_document\", title=title)\n",
        "                embeddings.append(response['embedding'])\n",
        "            except Exception as e:\n",
        "                print(f\"Error during embedding of document: {doc}\\nError: {e}\")\n",
        "                embeddings.append([])  # Add an empty list to maintain index alignment\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "def create_chroma_db(documents: List[str], path: str, name: str):\n",
        "    \"\"\"\n",
        "    Create (or load) a ChromaDB collection and add/update documents.\n",
        "    \"\"\"\n",
        "    client = chromadb.PersistentClient(path=path)\n",
        "    embedding_function = GeminiEmbeddingFunction()\n",
        "\n",
        "    try:\n",
        "        collection = client.get_collection(name=name, embedding_function=embedding_function)\n",
        "        print(f\"Loaded existing collection: {name}\")\n",
        "        if collection.count() == 0:\n",
        "            print(\"Existing collection is empty. Deleting and recreating.\")\n",
        "            client.delete_collection(name=name)\n",
        "            raise chromadb.db.base.NoDatapointsException # Force re-creation\n",
        "    except chromadb.db.base.NoDatapointsException:\n",
        "        print(\"Collection does not exist, creating a new one.\")\n",
        "    except Exception as e:  # General exception if collection exists but has other issues\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        print(\"Deleting potentially corrupted collection and recreating.\")\n",
        "        client.delete_collection(name=name)\n",
        "        # No 'raise' here, we want to continue to creation\n",
        "\n",
        "    collection = client.create_collection(name=name, embedding_function=embedding_function)\n",
        "    print(f\"Created new collection: {name}\")\n",
        "    embeddings = embedding_function(documents)\n",
        "\n",
        "    if not embeddings:\n",
        "        print(\"WARNING: Embeddings list is empty.\")\n",
        "    else:\n",
        "        if any(len(emb) == 0 for emb in embeddings): # Correct check for empty lists\n",
        "            print(\"WARNING: Some embeddings are empty lists.\")\n",
        "\n",
        "\n",
        "    collection.add(\n",
        "        documents=documents,\n",
        "        ids=[str(i) for i in range(len(documents))],\n",
        "        embeddings=embeddings,\n",
        "    )\n",
        "\n",
        "    print(f\"Collection count: {collection.count()}\")\n",
        "    return collection, name\n",
        "\n",
        "\n",
        "def print_dictionary(my_dict):\n",
        "    for key, value in my_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "def get_relevant_passage(query: str, db, n_results: int):\n",
        "    \"\"\"\n",
        "    Retrieve relevant passages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = db.query(query_texts=[query], n_results=n_results)  # Query with a list\n",
        "        print(\"ChromaDB Query Results:\")\n",
        "        print_dictionary(results) # print results\n",
        "        return results.get(\"documents\", [])  # Default to empty list if 'documents' key is missing\n",
        "    except Exception as e:\n",
        "        print(f\"Error during ChromaDB query: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def make_rag_prompt(query: str, relevant_passage: str):\n",
        "    prompt = f\"\"\"\n",
        "    Please repeat the question and give me the results base on the relevant passage.\n",
        "    Question: {query}\n",
        "    Relevant passage: {relevant_passage}\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "def generate_answer(prompt: str):\n",
        "    gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\"Gemini API Key not provided.\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    try:\n",
        "        result = model.generate_content(prompt)\n",
        "        return result.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating answer: {e}\")\n",
        "        return \"Sorry, I couldn't generate an answer.\"\n",
        "\n",
        "\n",
        "\n",
        "db, db_name = create_chroma_db(chunked_text, db_path, db_name)\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "query = input(\"Please enter your query: \")\n",
        "relevant_text = get_relevant_passage(query, db, n_results=3)\n",
        "\n",
        "if relevant_text:\n",
        "    flattened_relevant_text = [item for sublist in relevant_text for item in sublist]\n",
        "    final_prompt = make_rag_prompt(query, \"\".join(flattened_relevant_text))\n",
        "    answer = generate_answer(final_prompt)\n",
        "    print(\"\\nGenerated Answer:\", answer)\n",
        "else:\n",
        "    print(\"No relevant information found for the given query.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def print_dictionary(my_dict):\n",
        "    for key, value in my_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "def get_relevant_passage(query: str, db, n_results: int):\n",
        "    \"\"\"\n",
        "    Retrieve relevant passages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        results = db.query(query_texts=[query], n_results=n_results)  # Query with a list\n",
        "        print(\"ChromaDB Query Results:\")\n",
        "        print_dictionary(results) # print results\n",
        "        return results.get(\"documents\", [])  # Default to empty list if 'documents' key is missing\n",
        "    except Exception as e:\n",
        "        print(f\"Error during ChromaDB query: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def make_rag_prompt(query: str, relevant_passage: str):\n",
        "    prompt = f\"\"\"\n",
        "    Please repeat the question and give me the results base on the relevant passage.\n",
        "    Question: {query}\n",
        "    Relevant passage: {relevant_passage}\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "def generate_answer(prompt: str):\n",
        "    gemini_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\"Gemini API Key not provided.\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    try:\n",
        "        result = model.generate_content(prompt)\n",
        "        return result.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating answer: {e}\")\n",
        "        return \"Sorry, I couldn't generate an answer.\"\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "query = input(\"Please enter your query: \")\n",
        "relevant_text = get_relevant_passage(query, db, n_results=3)\n",
        "\n",
        "if relevant_text:\n",
        "    flattened_relevant_text = [item for sublist in relevant_text for item in sublist]\n",
        "    final_prompt = make_rag_prompt(query, \"\".join(flattened_relevant_text))\n",
        "    answer = generate_answer(final_prompt)\n",
        "    print(\"\\nGenerated Answer:\", answer)\n",
        "else:\n",
        "    print(\"No relevant information found for the given query.\")\n",
        "\n",
        "\n",
        "# what is the base rate of rolling a 5 star character"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "JKedFW3NPBlz",
        "outputId": "55e1dc9f-9c5f-4a67-9fdb-38dc91266581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 158\n",
            "DB Path: /content/chroma_db\n",
            "Number of chunks: 158\n",
            "DB Path: /content/chroma_db\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'chromadb.db.base' has no attribute 'NoDatapointsException'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidCollectionException\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4f5886b4f5dd>\u001b[0m in \u001b[0;36mcreate_chroma_db\u001b[0;34m(documents, path, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded existing collection: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/client.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(self, name, embedding_function, data_loader)\u001b[0m\n\u001b[1;32m    170\u001b[0m     ) -> Collection:\n\u001b[0;32m--> 171\u001b[0;31m         model = self._server.get_collection(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/telemetry/opentelemetry/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrace_granularity\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtracer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rate_limit_enforcer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/rate_limit/simple_rate_limit/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/segment.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(self, name, tenant, database)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidCollectionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Collection {name} does not exist.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidCollectionException\u001b[0m: Collection rag_experiment does not exist.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4f5886b4f5dd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_chroma_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;31m# --- Main Execution ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4f5886b4f5dd>\u001b[0m in \u001b[0;36mcreate_chroma_db\u001b[0;34m(documents, path, name)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoDatapointsException\u001b[0m \u001b[0;31m# Force re-creation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoDatapointsException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Collection does not exist, creating a new one.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# General exception if collection exists but has other issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'chromadb.db.base' has no attribute 'NoDatapointsException'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvrYoScJ3kSd",
        "outputId": "e4800aba-9393-48fe-f653-7ef195a31ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m1.8/2.5 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/151.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.4/151.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m608.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVxnN-v43mES",
        "outputId": "18f8fda8-46ee-46c1-a162-8a5aa00054c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your LangSmith API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[google-vertexai]\"\n",
        "!pip install -qU langchain-google-vertexai"
      ],
      "metadata": {
        "id": "JWIB7jxkEQb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "#import vertexai\n",
        "#vertexai.init(project=\"your-project-id\", location=\"your-location\")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gemini-2.0-flash-001\", model_provider=\"google_vertexai\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "DB-O8wN-EVhm",
        "outputId": "b1a8283a-8427-45f4-ca93-a2ca0d452fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatVertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'model_name': 'gemini-2.... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-034d76ef7dc9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit_chat_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_chat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gemini-2.0-flash-001\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"google_vertexai\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36minit_chat_model\u001b[0;34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfigurable_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         return _init_chat_model_helper(\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_provider\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_provider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chat_models/base.py\u001b[0m in \u001b[0;36m_init_chat_model_helper\u001b[0;34m(model, model_provider, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_vertexai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatVertexAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mChatVertexAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmodel_provider\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"google_genai\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0m_check_pkg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"langchain_google_genai\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/chat_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     model_config = ConfigDict(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatVertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'model_name': 'gemini-2.... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model=\"text-embedding-004\")"
      ],
      "metadata": {
        "id": "9TuPSqz0I1n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zjjffKBI4-r",
        "outputId": "a4ff565b-59e2-4518-caa2-a439d74d2c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "jpBhqQW_I7V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(\n",
        "    model=\"gemini-1.5-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    max_retries=6,\n",
        "    stop=None,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "wpriabQeJo1v",
        "outputId": "51a7923b-177e-4e16-834d-efd34cc7df64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValidationError",
          "evalue": "1 validation error for ChatVertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'temperature': 0, 'max_t... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7a5ea5bd0d6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_google_vertexai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatVertexAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m llm = ChatVertexAI(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gemini-1.5-flash-001\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_google_vertexai/chat_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     model_config = ConfigDict(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/load/serializable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             warnings.warn(\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatVertexAI\n  Value error, Unable to find your project. Please provide a project ID by:\n- Passing a constructor argument\n- Using vertexai.init()\n- Setting project using 'gcloud config set project my-project'\n- Setting a GCP environment variable\n- To create a Google Cloud project, please follow guidance at https://developers.google.com/workspace/guides/create-project [type=value_error, input_value={'temperature': 0, 'max_t... 'default_metadata': ()}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk3fp68RgRIG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**TavilySearch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bB364YHVgQfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec5709c-b41b-4116-d7e4-2c2fa53c6e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tavily-python) (2.32.3)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.9.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from tavily-python) (0.28.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tavily-python) (2025.1.31)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->tavily-python) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->tavily-python) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tavily-python\n",
        "from google.colab import userdata  # For Colab secrets\n",
        "from tavily import TavilyClient\n",
        "\n",
        "def tavily_search(query, search_depth=\"basic\", time_range=None, include_answer=None, max_results=5, include_domains=None):\n",
        "    \"\"\"\n",
        "    Overlay function for Tavily API search.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The search query. necessary\n",
        "        search_depth (str): \"basic\" or \"advanced\".\n",
        "        time_range (str or None): Time filter, e.g., \"d\" (day), \"w\" (week), \"m\" (month), \"y\" (year).\n",
        "        include_answer (str): \"none\", \"basic\", or \"advanced\".\n",
        "        max_results (int): Number of results to return.\n",
        "        include_domains (list or None): List of domains to include (default is None).\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        dict: Search results from Tavily API.\n",
        "    \"\"\"\n",
        "\n",
        "    tavily_client = TavilyClient(userdata.get('TAVILY_API_KEY'))\n",
        "    search_params = {\n",
        "      \"query\": query,\n",
        "      \"search_depth\": search_depth,\n",
        "      \"max_results\": max_results,\n",
        "    }\n",
        "\n",
        "    if time_range in [\"y\", \"m\", \"w\", \"d\"]:\n",
        "        search_params[\"time_range\"] = time_range\n",
        "    if include_answer in [\"basic\", \"advanced\"]:  # 只允許 Tavily API 支援的值\n",
        "        search_params[\"include_answer\"] = include_answer\n",
        "    if include_domains:\n",
        "        search_params[\"include_domains\"] = include_domains\n",
        "\n",
        "    response = tavily_client.search(**search_params)\n",
        "    return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooP2j8SGkfSF"
      },
      "outputs": [],
      "source": [
        "# Test tavily_search\n",
        "result1 = tavily_search(\"Latest AI news\")\n",
        "print(result1)\n",
        "\n",
        "# result2 = tavily_search(\"Latest AI news\", include_domains=[\"reddit.com\"])\n",
        "# print(result2)\n",
        "\n",
        "# result3 = tavily_search(\"Future of AI\", time_range = \"d\", max_results=1, search_depth = \"basic\", include_answer = \"basic\", include_domains=[\"medium.com\", \"techcrunch.com\"])\n",
        "# print(result3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def format_result_as_json(result):\n",
        "    \"\"\"\n",
        "    將結果格式化成易讀的 JSON 格式。\n",
        "    \"\"\"\n",
        "    formatted_result = {\n",
        "        \"query\": result[\"query\"],\n",
        "        \"follow_up_questions\": result[\"follow_up_questions\"],\n",
        "        \"answer\": result[\"answer\"],\n",
        "        \"images\": result[\"images\"],\n",
        "        \"results\": [\n",
        "            {\n",
        "                \"url\": item[\"url\"],\n",
        "                \"title\": item[\"title\"],\n",
        "                \"content\": item[\"content\"],\n",
        "                \"score\": item[\"score\"]\n",
        "            }\n",
        "            for item in result[\"results\"]\n",
        "        ],\n",
        "        \"response_time\": result[\"response_time\"]\n",
        "    }\n",
        "\n",
        "    # 美化輸出的 JSON 格式\n",
        "    json_output = json.dumps(formatted_result, ensure_ascii=False, indent=4)\n",
        "    return json_output"
      ],
      "metadata": {
        "id": "r86S7bb_7HtE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Crawler on certain website [reddit.com]**"
      ],
      "metadata": {
        "id": "SXecrpEQ4sYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw requests beautifulsoup4\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"J51PzebYQY_vynvS7KUBOw\",\n",
        "    client_secret=\"Kwf1A10ku-7VDRksvtS74-w3gCyPoQ\",\n",
        "    user_agent=\"chatbot\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqJJt-UN7K4k",
        "outputId": "c6e02b0f-7d92-4eb6-adf8-186c821729ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def checkTargetWeb(url):\n",
        "    \"\"\"\n",
        "    Check if the url is target url. If true, crawl the post title, content and top five comments.\n",
        "    Target url: reddit.com\n",
        "    \"\"\"\n",
        "    if \"reddit.com\" in url:\n",
        "        print(f\"It's a Reddit url: {url}\")\n",
        "        try:\n",
        "            post_id = url.split(\"/\")[-3]  # Get Reddit post ID\n",
        "            submission = reddit.submission(id=post_id)\n",
        "\n",
        "            title = submission.title.strip()\n",
        "            content = submission.selftext.strip()\n",
        "\n",
        "            # crawl top 5 comment\n",
        "            submission.comments.replace_more(limit=0)  # remove \"load more comments\"\n",
        "            comments = [comment.body.strip() for comment in submission.comments[:5]]\n",
        "\n",
        "            # convert to json\n",
        "            reddit_data = {\n",
        "                \"title\": title,\n",
        "                \"content\": content,\n",
        "                \"comments\": comments\n",
        "            }\n",
        "\n",
        "            print(reddit_data)\n",
        "\n",
        "            return reddit_data\n",
        "        except Exception as e:\n",
        "            print(f\"Can't crawl Reddit: {e}\")\n",
        "            return None\n",
        "    # TODO: genshin-impact.fandom.com\n",
        "    # else:\n",
        "\n",
        "\n",
        "result = tavily_search(\"How to quickly earn money in Genshin?\", include_domains=[\"reddit.com\", \"genshin-impact.fandom.com\"])\n",
        "print(format_result_as_json(result))\n",
        "for result_item in result['results']:\n",
        "    url = result_item['url']\n",
        "    checkTargetWeb(url)\n",
        "    # print(checkTargetWeb(url))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zXKv8r4rSOA",
        "outputId": "6c84989f-291d-4559-ce6a-5ba734a953ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"query\": \"How to quickly earn money in Genshin?\",\n",
            "    \"follow_up_questions\": null,\n",
            "    \"answer\": null,\n",
            "    \"images\": [],\n",
            "    \"results\": [\n",
            "        {\n",
            "            \"url\": \"https://www.reddit.com/r/Genshin_Impact/comments/qqvnw5/best_ways_to_farm_mora_without_using_resin/\",\n",
            "            \"title\": \"Best Ways to Farm Mora (without using resin)? : r/Genshin_Impact - Reddit\",\n",
            "            \"content\": \"Other people have already suggested the usual and more efficient ways to earn mora but if you're really desperate, you can sell artifacts by trashing them. You can also farm artifacts daily from investigations spots. Just make sure you investigate the artifact spots since you only have a max of 100 investigation spots per day.\",\n",
            "            \"score\": 0.6021791\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://www.reddit.com/r/Genshin_Impact/comments/wkdena/quick_guide_to_farm_mora_without_spending_resin/\",\n",
            "            \"title\": \"Quick guide to farm Mora without spending resin : r/Genshin_Impact - Reddit\",\n",
            "            \"content\": \"1) Daily artifact route (TL;DR: ~80.000 mora in 15 minutes; average 5333 mora/minute). https://www.reddit.com/r/GenshinImpactTips/comments/tk3jzh/ver_25_129_daily_artifact_routes_around_76k_79k/ A very important note: you do NOT need to do a complete artifact route (spending ~15min) if you don't have much free time, you also can do a \\\"half-way route\\\" and only visit the \\\"best spots\\\", spending like 5 min/day to get ~30k mora. Here is a guide: https://www.reddit.com/r/GenshinImpactTips/comments/ozwlz4/just_4mins_per_day_to_net_you_15k_mora_and_4_x/ A big shoutout to enxi0 for showing me this heavily optimized elite farm route: it's a 100 elite farm route that will take around 20 min, giving 35.000 mora + 15.000 xp artifact (which is equal to 15.000 mora), so around 50.000 mora in 20 minutes: https://imgur.com/gallery/kUVwyuu . 2) Daily expeditions (TL;DR: 25.000 mora/day)\",\n",
            "            \"score\": 0.57723385\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://www.reddit.com/r/GenshinImpactTips/comments/qm8gxi/you_can_get_at_least_33_wishes_per_patch_as_an/\",\n",
            "            \"title\": \"You can get at least 33 Wishes per Patch as an F2P player, and ... - Reddit\",\n",
            "            \"content\": \"Exactly. It's actually funny that people generally consider Welkin and BP good deals. They are absolutely terrible deals but comparing to buying gems they look amazing. Everything around Genshin's gacha system is very well designed to make you feel your money is spend well even though you're actually getting so little.\",\n",
            "            \"score\": 0.5409972\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://www.reddit.com/r/Genshin_Impact/comments/n70qdr/realm_currency_stacking_in_different_realms/\",\n",
            "            \"title\": \"Realm currency stacking in different realms : r/Genshin_Impact - Reddit\",\n",
            "            \"content\": \"In a way it does take some of the burden off if you just want to play Animal Crossing in Genshin. But in relation to pure Genshin gameplay experience, I do agree it totally takes some of the fun out of 'min-maxing and level grinding' for this part of the game, since we hit the ceiling for adeptal energy so fast.\",\n",
            "            \"score\": 0.43799233\n",
            "        },\n",
            "        {\n",
            "            \"url\": \"https://www.reddit.com/r/Genshin_Impact/comments/14u41yn/the_most_efficient_use_of_your_realm_currency/\",\n",
            "            \"title\": \"The most efficient use of your Realm Currency (Teapot coins)\",\n",
            "            \"content\": \"This is the official community for Genshin Impact (原神), the latest open-world action RPG from HoYoverse. The game features a massive, gorgeous map, an elaborate elemental combat system, engaging storyline & characters, co-op game mode, soothing soundtrack, and much more for you to explore!\",\n",
            "            \"score\": 0.42993253\n",
            "        }\n",
            "    ],\n",
            "    \"response_time\": 1.71\n",
            "}\n",
            "It's a Reddit url: https://www.reddit.com/r/Genshin_Impact/comments/qqvnw5/best_ways_to_farm_mora_without_using_resin/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Best Ways to Farm Mora (without using resin)?', 'content': \"So I noticed many streamers have millions of Mora constantly, and I never see them farming ley lines. Are there methods of farming mora that doesn't require resin? Would love to hear everyone's suggestions or tricks. \\n\\nThanks in advance! \\n\\n- A very broke Genshin player\", 'comments': ['\\\\- Bounties / Requests\\n\\n\\\\- Surveys\\n\\n\\\\- Events\\n\\n\\\\- Paimon shop (the limited 10 one, not the unlimited 20)\\n\\n\\\\- Sigils from Liyue and Mondstadt (you can exchange them for moras)\\n\\n\\\\- Killing mobs but not worthy for moras, only if you need their drops\\n\\n&#x200B;\\n\\nBut the most \"efficient\" way is to farm golden leylines at higher world level you can get 60k per 20 resin.', 'It’s mainly from the events/ 2 weekly abyss reset. Most streamers will be day 1 players, you reach a point you barely have any new characters to build and amass a lot of spare resources.', \"artifact route gets you around 50K-70K a day.\\n\\nyes, it's the best way to farm mora without resin by far and away.\", 'I notice most people don’t continue to do Requests/Bounties every week after maxing out reputation, which will still net you a lot of mora weekly even after capping out. I’m always telling people to keep doing them for the mora alone', 'Farm elites:\\n\\n[https://redd.it/jd4ia1](https://redd.it/jd4ia1)\\n\\n[https://redd.it/pj2lbz](https://redd.it/pj2lbz)']}\n",
            "It's a Reddit url: https://www.reddit.com/r/Genshin_Impact/comments/wkdena/quick_guide_to_farm_mora_without_spending_resin/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Quick guide to farm Mora without spending resin', 'content': 'There are basically 3 ways to farm mora daily without spending resin. Some ways are more time-efficient or easier than others, so I\\'m also taking \"**time spent**\" into consideration. And I\\'m also considering that you\\'re playing on a *fairly* \"fast\" device (PC/mobile/console) and not a toaster.\\n\\nFor example, if you take more than +30 seconds to teleport in-game, you have a slow device and the \"estimated time\" to finish the tasks below will increase considerably. If you have an insanely fast loading-screen device (like PS5), the time below will be even lower.\\n\\n&#x200B;\\n\\n**1) Daily artifact route (TL;DR: \\\\~80.000 mora in 15 minutes; average 5333 mora/minute).**\\n\\nIt is, by far, the best method to farm Mora and/or artifact xp without spending resin. Personally, I strongly recommend all players, who want to get their account \"stronger\", to do the artifact route whenever they can.\\n\\nThere are several artifact routes you can do, some routes are more time-efficient than others, but overall it won\\'t change much, so you\\'ll be fine following whichever guide you prefer. Here, 2 guides for the artifact route as an example:\\n\\n[https://www.reddit.com/r/GenshinImpactTips/comments/tk3jzh/ver\\\\_25\\\\_129\\\\_daily\\\\_artifact\\\\_routes\\\\_around\\\\_76k\\\\_79k/](https://www.reddit.com/r/GenshinImpactTips/comments/tk3jzh/ver_25_129_daily_artifact_routes_around_76k_79k/)\\n\\n[https://www.reddit.com/r/GenshinImpactTips/comments/syk5bs/artifact\\\\_route\\\\_120\\\\_artifacts\\\\_in\\\\_less\\\\_than\\\\_15/](https://www.reddit.com/r/GenshinImpactTips/comments/syk5bs/artifact_route_120_artifacts_in_less_than_15/)\\n\\n**A very important note:** you do NOT need to do a complete artifact route (spending \\\\~15min) if you don\\'t have much free time, you also can do a \"half-way route\" and only visit the \"best spots\", spending like 5 min/day to get \\\\~30k mora. At the end of the day, it\\'s better to get \\\\~30k mora/day (210k mora/week) than 0 mora, right? Do whatever is best for you.\\n\\n&#x200B;\\n\\n**2) Random events (TL;DR: \\\\~15.000 mora in 4 minutes; average 3750 mora/minute).**\\n\\nThere is one spot in Inazuma where we can 100% trigger the random event \"Feed the dog\" and repeat. Each event gives 15xp friendship for the whole team + \\\\~1500 mora + maybe enhancement ores. We can do 10 random events every day, each event gives between \\\\~1050 to 1950 mora (average of 1500 mora/event), so **15.000 mora/day**.\\n\\nHere is a guide: [https://www.reddit.com/r/GenshinImpactTips/comments/ozwlz4/just\\\\_4mins\\\\_per\\\\_day\\\\_to\\\\_net\\\\_you\\\\_15k\\\\_mora\\\\_and\\\\_4\\\\_x/](https://www.reddit.com/r/GenshinImpactTips/comments/ozwlz4/just_4mins_per_day_to_net_you_15k_mora_and_4_x/)\\n\\n&#x200B;\\n\\n**3) Farm elite enemies (TL;DR: \\\\~50.000 mora in 20 minutes; average 2500 mora/minute)**\\n\\nBasically, you\\'ll kill mobs in the overworld, focusing on elite mobs, which can give 200/400/600 mora each. It\\'s not a time-efficient way to farm mora **IF** you don\\'t have a \"strong\" team comp that can kill these mobs quickly. That\\'s why I\\'d say this farm is more oriented towards the endgamer players, because they can speedrun this route.\\n\\nA big shoutout to [**enxi0**](https://www.reddit.com/user/enxi0/) for showing me this heavily optimized elite farm route: it\\'s a 100 elite farm route that will take around 20 min, giving 35.000 mora + 15.000 xp artifact (which is equal to 15.000 mora), so around 50.000 mora in 20 minutes: [https://imgur.com/gallery/kUVwyuu](https://imgur.com/gallery/kUVwyuu) . This route was made based on a 4-player Co-op farming but, of course, you can play solo if you want.\\n\\nBtw, if you have friends to play Co-op, doing this route is way more fun than doing solo.\\n\\nAnd if you wanna know more about elite farming, this is a really good video I recommend to watch: [https://www.youtube.com/watch?v=wpVVNXwt0Sw](https://www.youtube.com/watch?v=wpVVNXwt0Sw)\\n\\n&#x200B;\\n\\n**4) Conclusion: At the end of the day, if you do all 3 methods above, you\\'ll get around 80.000 + 15.000 + 50.000 = 145.000 mora, spending 15 + 4 + 20 = 39 minutes in total.**\\n\\n&#x200B;\\n\\n# Honor mentions (some \"obvious\" things to do daily / weekly):\\n\\n**1)** [**Genshin daily login**](https://webstatic-sea.mihoyo.com/ys/event/signin-sea/index.html?act_id=e202102251931481&lang=en-us)**. (TL;DR: 54.000 mora in one month; average of 10.800 mora/min).**\\n\\nYes, the daily login rewards are very underwhelming. However, takes literally less than 10 seconds to claim the reward (go to the link, click the reward, done). In 30 days, we get a total of 54.000 mora and we spend 30\\\\*10 seconds = 300 seconds = 5min, so roughly 10.800 mora/min. Which is not bad, all things considered. The main problem is to \"remember\" to login and claim the rewards every single day.\\n\\n&#x200B;\\n\\n**2) Daily expeditions (TL;DR: 25.000 mora/day)**\\n\\nBasically you just need to put all 5 expeditions to get 5000 mora in 20 hours. Come next day and claim the 25.000 mora and redo the expeditions.\\n\\nYou can \"min-max\" the mora using the 20h expeditions with Bennett, Fischl, Chongyun, Keqing and Sara (will take 15 hours), then come back 15h later to collect 25.000 mora, and then use the 12 hours expeditions with these same characters (will take 9 hours), and then 9 hours later collect more 12.500 mora, giving a total of 37.500 mora in 24 hours. Of course, this method is annoying to do on a daily basis, that\\'s why I recommend to use the 20 hours expeditions and only come back the next day.\\n\\n&#x200B;\\n\\n**3) Daily commissions (TL;DR: roughly 30.000 - 40.000 mora/day at AR55-59; AR60 players get an additional 15.000 mora/day).**\\n\\nMost players do daily commissions to get primogems, AR XP and friendship, but we also get a fairly amount of mora spending between 3 to 10 minutes to finish all 4 commissions. One more reason to do the dailies.\\n\\n&#x200B;\\n\\n**4) Weekly bounties and requests (TL;DR: 150.000 mora/week)**\\n\\nWe are limited to do only 3 bounties + 3 requests every week but they\\'re fairly quick to complete. So if we spend like 10 minutes to finish everything, we get an average of 15.000 mora/minute, which is really good (time-wise).\\n\\n&#x200B;\\n\\n**5) Conclusion: doing all these 4 \"obvious\" things, we get a total of 2.454.000 mora in 30 days.**', 'comments': ['Genshin Burnout Speedrun Any%', \"Might as well add that you get a nontrivial amount while claiming domains and bosses, too, even though thats not why you spent your resin there. AR60 adds another 9k/day here.\\n\\nAlso abyss gives 585k twice a month. That's around 10k/min.\\n\\nTeapot is 200k/week as well.\\n\\nWith all the free sources there's pretty much no reason to do mora leylines at all.\", 'Thanks for posting this!! I try and do a modified artifact run everyday, which I have fun doing cause I just genuinely love to run around Liyue and try new team comps/ just enjoy the environment. I really appreciate you adding the elite boss route! Me and my bf will be trying that in co-op later today 🤗', 'I do the daily artifact route but not the elite enemies. I guess I should consider that one as well.', \"That's a lot of work and time compared to just spending your daily resin on 4 doubled leylines to get 480,000 mora a day...I highly suggest running leylines to burn resin if you're worried about running out of Mora.\"]}\n",
            "It's a Reddit url: https://www.reddit.com/r/GenshinImpactTips/comments/qm8gxi/you_can_get_at_least_33_wishes_per_patch_as_an/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'You can get at least 33 Wishes per Patch as an F2P player, and up to 81 Wishes with full Spiral Abyss clear + Welkin + BP. Detailed breakdown of recurring Primogem/Fate income in the post body.', 'content': '**TL;DR at bottom**\\n\\nI\\'ve been seeing a ton of posts lately about how many primos you can get in X time and whether there\\'s enough time to farm enough primos for Y character. In light of this, I wanted to provide a break down of all possible **recurring** sources of Primogems to give people a better idea of their Primogem income and subsequently use that to plan for future banners.\\n\\nThis does **NOT** include **one-time** sources of Primos, but those can also net you a substantial amount of Primos too if you haven\\'t completed all the game\\'s content, including:\\n\\n* Adventuring (discovering new Waypoints, Domains, Statues, raising Adventure Ranks, etc.)\\n* Quests\\n* Chests\\n* Inviting Characters to designated Furniture Sets\\n* Character Hangouts\\n* Achievements\\n\\n**F2P:**\\n\\n|**Source**|**Income**|**Adjusted for Primos per Week**|\\n|:-|:-|:-|\\n|Daily Commissions|60 Primos per day|420 per week|\\n|Events|\\\\~420 Primos per 2 weeks (varies)|210 per week|\\n|Stardust Shop|5 Fates per month\\\\*|185 per week|\\n|Maintenance Compensation|300 per 6 weeks|50 per week|\\n|HoYoLab Check-in|60 Primos per month|14 per week|\\n|Event Banner Free Trial|20 Primos per 3 weeks|6.7 per week|\\n|Spiral Abyss Floors 9-12|600 twice per month (based on how many stars you can get)|277 per week (max)|\\n\\n\\\\*assuming we only care about Intertwined Fates\\n\\n* Total without Spiral Abyss clear: **5,307 Primos per Patch** (released every 6 weeks) or **33 Fates**\\n* Total with full Spiral Abyss clear: **6,964 Primos per Patch** or **43 Fates**\\n\\n**Non-F2P:**\\n\\n|**Source**|**Income**|**Adjusted for Primos per Week**|\\n|:-|:-|:-|\\n|Welkin Moon (5 USD)|3,000 Primos per month|692 per week|\\n|Battle Pass Gnostic Hymn (10 USD)|680 Primos and 4 Intertwined Fates per 6 weeks|220 per week|\\n\\nIf we include the non-F2P sources of recurring Primos, they come out to about 912 Primos per week (roughly doubling the F2P income) for a total of:\\n\\n* (without Spiral Abyss clear) **10,770 Primos per Patch** or **67 Fates**\\n* (with full Spiral Abyss clear) **12,427 Primos per Patch** or **77 Fates**\\n\\n**TL;DR** **Possible Combinations:**\\n\\nFind the row that applies to you, count how many patches away your character is (speculated), and multiply by the \"Fates per Patch\" to see how many wishes you\\'ll have saved up by then. Reminder that you need about 75-80 Wishes for a 5-star character, and double that to prepare for the worst case scenario of losing the 50/50.\\n\\nKeep in mind this is the absolute minimum value that\\'s regularly attainable, and you will likely end up with more Fates if you include new content being released, bug compensations, bigger event rewards, etc.\\n\\n||Primos per Patch|Fates per Patch|Fates per Patch (recycling Starglitter for Fates)|\\n|:-|:-|:-|:-|\\n|F2P, no F9-12 Clear|5,308|33.2|34.8|\\n|F2P, full F9-12 Clear|6,964|43.5|45.7|\\n|BP, no F9-12 Clear|6,628|41.4|43.5|\\n|BP, full F9-12 Clear|8,284|51.8|54.4|\\n|Welkin, no F9-12 Clear|9,450|59.1|62.0|\\n|Welkin, full F9-12 Clear|11,107|69.4|72.9|\\n|BP + Welkin, no F9-12 Clear|10,770|67.3|70.7|\\n|BP + Welkin, full F9-12 Clear|12,427|77.7|81.6|\\n\\nThis also doesn\\'t account for bits of Starglitter you\\'ll obtain for spending your Standard Banner Fates occasionally. Those will net you maybe one or two extra Intertwined Fates per patch.', 'comments': ['Puts into perspective how much the damage control primos for the anniversary meant for the free to plays', \"I've been saying this in various posts that with Welkin and BP you are essentially guaranteed one 5 star per patch. Which, IMO, is fairly decent.\", 'Primogems come very often which is not an issue at all, especially if you can clear every content. The only things to worry are banners time (if you want multiple promoted in a row) and luck (pulls earlier than pity or winning 50/50). Which is really my struggle now since I want to pull Itto, Albedo and Xiao (rumoured on 2.4) with my saved 190 pulls for now.', 'tysm for this!', 'Thanks, I needed this cuz I am saving and farming hard for Ganyu rerun and Yae run. Currently at 28 pity, 70pulls and 50/50.']}\n",
            "It's a Reddit url: https://www.reddit.com/r/Genshin_Impact/comments/n70qdr/realm_currency_stacking_in_different_realms/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'Realm currency stacking in different realms', 'content': \"One of the achievements for the Serenitea pot is to get 20k Adeptal Energy in a single realm (map).  \\nThis has made me thinking - it clearly means that your adeptal energy in each realm is seperate.\\n\\nBut does that also mean once you've unlocked a second or even your third realm - and you get 20k adeptal energy there too, it'll have a different realm currency count?\\n\\nSay you'd have 30 coins/hour in realm 1.  \\nYou build up your adeptal energy in realm 2 to 12K and get 26 coins /h  \\nDoes that mean you'll get 56 total per hour, to a max of 90/h if you have all three realms unlocked and furnished to 20k adeptal points?\\n\\nBecause right now, even if you reach 30 coins/h, you cannot possibly buy out the store with the resin, EXP materials, etc, weekly.\", 'comments': [\"That'd be my guess since it's actually very easy to reach max. Already at 13k out of 20k and only Trust 5. So by the time I unlock another realm I'd be over the 20k\", \"I guess it's just for the achievement to get us primogems. The serenitea pot will just die off slowly if they don't improve it.  \\n\\n\\nMy thoughts on what they could improve for the serenitea pot:   \\n1) 30/hr for each realm, meaning 30 x 3 realms.  \\n2) Furniture that are crafted **AND** placed in current realm cannot be used for other realms, only those that has not placed could be brought over.   \\n3) A portal that connects instantly to the other layouts.   \\n4) Go back to the menu choices after pressing back from one of them instead of immediately exit off.\", \"So, after unlocking a second realm, it looks like the furniture is shareable between realms and the currency doesn't 'stack'. Maxed both realms at 20k+ energy and only recieved 30 realm currency at the end of the hour.\", 'I believe the max total is 30. I do not think you are meant to buy out the shop each week like its an event.  They just give you options.', 'The whole replenishing shop can be bought out weekly with 12,000 coins\\n\\n90/hr x 24hrs x 7days is 15,120 coins\\n\\nFrom those, it looks like it stacks so you can comfortably buy the weekly shop and still have spare']}\n",
            "It's a Reddit url: https://www.reddit.com/r/Genshin_Impact/comments/14u41yn/the_most_efficient_use_of_your_realm_currency/\n",
            "{'title': 'The most efficient use of your Realm Currency (Teapot coins)', 'content': \"&#x200B;\\n\\nhttps://preview.redd.it/r5liu1jdqqab1.png?width=2560&format=png&auto=webp&s=70e2e39d33c1ce87161932b5a61735c65428c2c3\\n\\nHowdy Yall,\\n\\nI was working out what the most efficient use of my Realm Currency would be over a 1 week period and figured I would share for anyone who's interested. I'm sure this has probably been covered before but it can't hurt to have another post about it.\\n\\nIf you don't care for the details skip to the last paragraph/section (in bold) prior to the edit :)\\n\\n\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\n\\n**Initial Facts**:\\n\\n1. If your Realm Rank is 'Fit for a King' you will make **5040 RC** over 1 week (7 days)\\n2. Hero's Wit x1 costs 120 RC\\n3. 10K Mora costs 120 RC\\n4. Purple Artifact Exp Bottles (10k Exp) cost 360 RC\\n5. Blue Artifact Exp Bottles (2.5k Exp) cost 90 RC\\n6. Transient Resin x1 costs 1200 RC\\n\\n&#x200B;\\n\\n**Initial Calculations**:\\n\\n1. One run of an Exp Leyline at World Level 8 will net you 6.125 Hero's Wit (on average)\\n2. One run of a Mora Leyline at World Level 8 will net you 60,000 Mora\\n3. One run of an Artifact Domain at AR45 will net you (on average) 3.55 blue artifacts, 2.48 purple artifacts & 1.07 orange artifacts. This totals out to 10722.60 Artifact Exp WITHOUT including the orange artifact (as I would prefer to keep/strongbox them). Including the orange artifact brings the Exp total to 14502.6\\n\\n&#x200B;\\n\\n**Item RC value VS resin cost**:\\n\\n1. One run of an Exp Leyline is worth 660 RC (minimum) AND 735 RC (on average)\\n2. One run of a Mora Leyline is worth 720 RC\\n3. One run of an AR45 Artifact Domain is worth 522.1 RC (average) **OR** 386 RC if you do not include the orange artifact\\n4. Transient Resin gives 60 Original Resin which is equivalent to three runs, therefore one run is worth 400 RC\\n\\n\\\\_\\\\_\\\\_\\\\_\\\\_\\\\_\\n\\n&#x200B;\\n\\n**Best use of your 5040 RC each week for efficiency**:\\n\\n1. **Transient Resin x 1 (1200 RC)**\\n2. **Purple Artifact Exp Bottles x 5 (1800 RC)**\\n3. **Blue Artifact Exp Bottles x 20 (1800 RC)**\\n4. **Hero's Wit x 2 (240 RC) / 20k Mora (240 RC) OR save for furniture purchases**\\n\\nThe RC you need to buy your 2 Hero's Wit will be earned in the last 8 hours of your week. You don't need to worry too much about this because even if you buy it after the reset you will not miss out.\\n\\n&#x200B;\\n\\nDisclaimer: if you wanna buy furniture you do you boo, I'm pretty close to buying out my shop so I totally respect it :P\\n\\n&#x200B;\\n\\nEDIT: after receiving a comment regarding Exp Leylines I've decided to change the post to reflect the average Hero's Wit drops rather than the minimum. This changes the value of one run of the Exp Leyline to 735 RC which is 15 RC higher then the Mora Leyline. I would still generally recommend going for the Hero's Wit over the Mora because there are more alternative ways to get Mora than there are for Character Exp (at least with a decent level of efficiency).\", 'comments': ['Thanks for the detailed explanation. I always buy the Transient Resin and Artifacts potion, now I realized that I am actually making the right choice.', 'To all the people saying artifact routes, that’s fair and probably good to include in the post as a disclaimer or something, but that doesn’t discount this list being valuable for many people who don’t want to do those. I don’t have the stamina to grind those routes anymore (I used to) and I also don’t have the inventory space for it. (I know I can strongbox but still, so much time to just artifacts.) Idk maybe ignore me, I’ve hit the point where I let my resin cap almost every day so optimizing isn’t where my brain is at', 'Only transient resin for me since I build my teapot', 'Artifact routes are a quick way to burnout. This is much better imo', 'This is hilarious because this is almost exactly what I buy. Recently switching things up tho to buy out all hero wits tho since I went on a leveling spree.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZYmtd9h5jn"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Chroma DB** & **Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kP3WRo4HWWR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "cae7428a-4fcb-44d2-e64f-104b377a0d7f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: \" 'items.csv' \"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8f6e8f15dd80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### A template block for importing CSVs with info once we have some info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\" 'items.csv' \"\"\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \" 'items.csv' \""
          ]
        }
      ],
      "source": [
        "### A template block for importing CSVs with info once we have some info\n",
        "import csv\n",
        "with open(\"\"\" 'items.csv' \"\"\" ) as file:\n",
        "  lines = csv.reader(file)\n",
        "\n",
        "  documents = []\n",
        "  metadatas = []\n",
        "  ids = []\n",
        "\n",
        "  for i, line in enumerate(lines):\n",
        "    if i == 0:\n",
        "      continue    # skipping header\n",
        "      documents.append(line[1])\n",
        "      metadatas.append({\"item_id\": line[0]})\n",
        "      ids.append(str(id))\n",
        "      id+=1\n",
        "\n",
        "documents ## show documents to terminal after loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRjGOmdbFDEb"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRuBGmJMFvXI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "8b9fc0c0-a5c2-48cc-80b9-7256ea63900b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chromadb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-81a56c22a283>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchroma_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchromadb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "chroma_client = chromadb.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpCiPEhaW3Bh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "13b1f849-922c-41d3-9482-e4d47a08f6f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chromadb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d956b1d3aa6c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchromadb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddingFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGeminiEmbeddingFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbeddingFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDocuments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"\"\"Generates embeddings for a list of documents using Gemini API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        \"\"\"Generates embeddings for a list of documents using Gemini API.\"\"\"\n",
        "        model = genai.GenerativeModel(\"gemini-pro\")  # Ensure the right model is used\n",
        "        embeddings = []\n",
        "\n",
        "        for text in input:\n",
        "            response = model.embed_content(content=text, task_type=\"retrieval_document\")  # Adjust task type if needed\n",
        "            embeddings.append(response[\"embedding\"])  # Extract the embedding\n",
        "\n",
        "        return embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5AOk8J7F36J"
      },
      "outputs": [],
      "source": [
        "collection = chroma_client.create_collection(name=\"my_collection\", embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "collection.add(\n",
        "    documents= documents,\n",
        "    metadatas=metadatas,\n",
        "    ids=ids\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oegVy33GhYb"
      },
      "outputs": [],
      "source": [
        "results = collection.query(\n",
        "    query_texts=[\"This is a query document about genshin impact\"], # Chroma will embed this for you\n",
        "    n_results=5, # how many results to return\n",
        "    include=[\"distances\", \"metadatas\", \"documents\"] # what to return\n",
        ")\n",
        "results # shows results to terminal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArZUDAq1hrBC"
      },
      "source": [
        "\n",
        "\n",
        "--- ---\n",
        "\n",
        "\n",
        "**Gemini Chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gN9MFKJF5vrZ",
        "outputId": "34be2df8-2c3b-44f8-f7e7-a51e41059859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "All Gemini Models available for content generation: \n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro\n",
            "models/gemini-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro-vision\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-001\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash-001\n",
            "models/gemini-1.5-flash-001-tuning\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-1.5-flash-8b-exp-0827\n",
            "models/gemini-1.5-flash-8b-exp-0924\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/learnlm-1.5-pro-experimental\n",
            "----------------------------------------------------\n",
            "Hi I'm Paim0n, ready to assist you in the world of Teyvat!\n",
            "Current selected model:  gemini-pro\n",
            "You: How to earn money quickly in Genshin?\n",
            "{'query': 'How to earn money quickly in Genshin?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Genshin Impact Mora Farming | How to make money quickly', 'url': 'https://www.gamerevolution.com/guides/662385-genshin-impact-mora-farming-currency-quick-money', 'content': 'Genshin Impact Mora Farming | How to make money quickly - GameRevolution Genshin Impact Mora Farming | How to make money quickly Genshin Impact Mora farming will let players earn some quick cash. There are a few different ways in which players can farm Mora in Genshin Impact. How to farm Mora in Genshin Impact Mora is incredibly useful in\\xa0Genshin Impact. How to farm Mora in Genshin Impact There are many different ways of earning Mora in Genshin Impact. Farming Sigils is the best way to farm Mora. android Genshin Impact Genshin Impact guide iOS miHoYo open world PC PS4 RPG Genshin Impact Diona Build: Best Weapons, Artifacts, and Team Comps Genshin Impact Mona Build: Best Weapons, Artifacts, and Team Comps', 'score': 0.82761955, 'raw_content': None}, {'title': 'What is the fastest way to get a 10 pull? : r/Genshin_Impact - Reddit', 'url': 'https://www.reddit.com/r/Genshin_Impact/comments/sqs6mj/what_is_the_fastest_way_to_get_a_10_pull/', 'content': 'If you find yourself low on options, go to genshin interactive map and find every chest everywhere. Achievement hunt. If that all fails. Yeah, maybe look up some online ways to make cash. A welkin moon would get you like 4 summons in the next 3 days with commissions.', 'score': 0.7366474, 'raw_content': None}, {'title': 'How to Earn Money in Genshin Impact: Your Quick Guide', 'url': 'https://www.playbite.com/how-to-earn-money-in-genshin-impact/', 'content': 'How to Earn Money in Genshin Impact: Your Quick Guide - Playbite How to Earn Money in Genshin Impact: Your Quick Guide Genshin Impact Playbite is an app that lets you play casual mobile games and win awesome rewards like official App Store and Play Store gift cards. You can use these cards to grab items in Genshin Impact, helping you earn that precious Mora and Primogems. Download Playbite now, start playing, and turn your gaming skills into real rewards that can boost your Genshin Impact experience. 500k winners and counting... How to Win the 50/50 in Genshin Impact -------------------------------------- Should You Play Genshin Impact? Should You Use Your Wishes in Genshin Impact? 500k winners and counting...', 'score': 0.69274646, 'raw_content': None}, {'title': 'Quick guide to farm Mora without spending resin : r/Genshin_Impact - Reddit', 'url': 'https://www.reddit.com/r/Genshin_Impact/comments/wkdena/quick_guide_to_farm_mora_without_spending_resin/', 'content': '1) Daily artifact route (TL;DR: ~80.000 mora in 15 minutes; average 5333 mora/minute). https://www.reddit.com/r/GenshinImpactTips/comments/tk3jzh/ver_25_129_daily_artifact_routes_around_76k_79k/ A very important note: you do NOT need to do a complete artifact route (spending ~15min) if you don\\'t have much free time, you also can do a \"half-way route\" and only visit the \"best spots\", spending like 5 min/day to get ~30k mora. Here is a guide: https://www.reddit.com/r/GenshinImpactTips/comments/ozwlz4/just_4mins_per_day_to_net_you_15k_mora_and_4_x/ A big shoutout to enxi0 for showing me this heavily optimized elite farm route: it\\'s a 100 elite farm route that will take around 20 min, giving 35.000 mora + 15.000 xp artifact (which is equal to 15.000 mora), so around 50.000 mora in 20 minutes: https://imgur.com/gallery/kUVwyuu . 2) Daily expeditions (TL;DR: 25.000 mora/day)', 'score': 0.5928793, 'raw_content': None}, {'title': 'How to Make Money in Genshin Impact: Easy Tips for Earning Mora and ...', 'url': 'https://www.playbite.com/how-to-make-money-in-genshin-impact/', 'content': 'How to Make Money in Genshin Impact: Easy Tips for Earning Mora and Primogems - Playbite How to Make Money in Genshin Impact: Easy Tips for Earning Mora and Primogems Genshin Impact So, how exactly can you boost your in-game wealth in Genshin Impact? Turning Genshin Impact Winnings to Real-World Rewards Did you know you can turn your Genshin Impact expertise into real-world rewards? These can then be used to grab Mora, Primogems, and other in-game currencies in Genshin Impact. Let your passion for gaming in Genshin Impact help you score more in-game currencies and even snag some real-world goodies! 500k winners and counting... How to Win the 50/50 in Genshin Impact -------------------------------------- Should You Play Genshin Impact? 500k winners and counting...', 'score': 0.52422476, 'raw_content': None}], 'response_time': 1.56}\n",
            "Paim0n:  **Quick Ways to Earn Mora in Genshin Impact**\n",
            "\n",
            "1. **Daily Commissions:** Complete daily commissions to earn Mora, Adventure EXP, and other rewards.\n",
            "\n",
            "2. **Ley Line Outcrops:** Defeat enemies in Ley Line Outcrops to earn Mora and EXP materials. Focus on defeating enemies quickly and efficiently.\n",
            "\n",
            "3. **Artifact Route:** Farm artifact domains daily for a chance to obtain valuable artifacts. Sell unwanted artifacts for Mora.\n",
            "\n",
            "4. **Elite Enemy Farming:** Defeat elite enemies, such as bosses and Fatui agents, for a significant amount of Mora.\n",
            "\n",
            "5. **Serenitea Pot:** Place valuable furnishings in your Serenitea Pot to increase your Adeptal Energy and earn Mora.\n",
            "\n",
            "6. **Events:** Participate in in-game events that offer Mora as a reward.\n",
            "\n",
            "7. **Blossom of Wealth:** Use the Blossom of Wealth gadget to collect Mora from flowers and other sources.\n",
            "\n",
            "8. **Parametric Transformer:** Convert unwanted materials into Mora using the Parametric Transformer.\n",
            "\n",
            "9. **Battle Pass:** Purchase the Battle Pass to earn Mora and other rewards as you level up.\n",
            "\n",
            "10. **Abyss Spiral:** Challenge the Abyss Spiral for Mora and other valuable rewards.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai\n",
        "import google.generativeai as genai\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import userdata\n",
        "# Configure the Gemini API\n",
        "secret = userdata.get('GOOGLE_API_KEY')          ### extract API key from notebook secret\n",
        "  #secret = \"AIzaSyDv2HGggXnDdAbhG6jvaBxfXraGr3iBEjw\"  ### my API key\n",
        "genai.configure(api_key=secret)\n",
        "\n",
        "# store conversation history\n",
        "conversation_history = []\n",
        "\n",
        "def get_embedding(text, model=\"models/embedding-001\"):\n",
        "    \"\"\"Generate an embedding vector for a given text.\"\"\"\n",
        "    response = genai.embed_content(model=model, task_type=\"semantic_similarity\", content=text)\n",
        "    return response.get([\"embedding\"], [])  # Returns the embedding vector\n",
        "\n",
        "    # Store conversation history\n",
        "    conversation_history = []\n",
        "\n",
        "def generate_response(user_input):\n",
        "    \"\"\"Generate a response using Gemini LLM with context-aware embeddings.\"\"\"\n",
        "    global conversation_history\n",
        "\n",
        "    conversation_history.append({\"role\": \"user\", \"parts\": user_input})\n",
        "\n",
        "    # Use the Gemini model to generate a response\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    response = genai.chat(messages=conversation_history).text\n",
        "\n",
        "    # Add AI response to history\n",
        "    bot_response = response.text\n",
        "    conversation_history.append({\"role\": \"user\", \"parts\": bot_response})\n",
        "\n",
        "    return bot_response\n",
        "\n",
        "# Show available models for content generation:\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"All Gemini Models available for content generation: \")\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "\n",
        "# Initialize chat session\n",
        "selected_model = 'gemini-pro'\n",
        "model = genai.GenerativeModel(selected_model)\n",
        "system_message = (\n",
        "    \"You are Paim0n, an AI guide specialized in assisting players with the video game Genshin Impact, developed by HoYoverse. \"\n",
        "    \"Your role is to provide accurate and up-to-date information on all aspects of the game, including characters, builds, artifacts, weapons, \"\n",
        "    \"team compositions, game mechanics, event guides, exploration tips, and lore discussions. \"\n",
        "\n",
        "    \"You also help players complete quests by providing step-by-step guidance, puzzle solutions, and strategies for difficult encounters. \"\n",
        "    \"Additionally, you assist with finding rare items by providing detailed locations, farming routes, estimated respawn times, and the best methods to obtain them efficiently. \"\n",
        "    \"If players are looking for a specific area or an unfamiliar location, you offer navigation assistance, waypoints, and travel tips to help them reach their destination easily. \"\n",
        "\n",
        "    \"You should stay within the context of Genshin Impact and avoid answering unrelated questions. \"\n",
        "    \"If asked about leaks or unofficial content, politely inform the user that you only provide officially released information. \"\n",
        "    \"Maintain an energetic and friendly tone, just like the real Paimon, but avoid excessive repetition or filler phrases. \"\n",
        "\n",
        "    \"Your goal is to be the ultimate Genshin Impact companion, helping players optimize their experience, whether they need battle strategies, exploration guidance, \"\n",
        "    \"or tips on maximizing their resources efficiently.\"\n",
        ")\n",
        "# chat = model.start_chat(history=[{\"role\": \"system\", \"parts\": system_message}])\n",
        "# start chat\n",
        "chat = model.start_chat(history=[])\n",
        "# send system message as the first message and wait for completion\n",
        "response = chat.send_message(system_message)\n",
        "if response:  # ensure system message is processed before continuing\n",
        "  print(\"Hi I'm Paim0n, ready to assist you in the world of Teyvat!\")\n",
        "else:\n",
        "  print(\"System message not passed\")\n",
        "\n",
        "# Verify chosen model\n",
        "for m in genai.list_models():\n",
        "  model_name = m.name.split(\"/\")[-1]\n",
        "  if model_name == selected_model:\n",
        "    # print(\"----------------------------------------------------\")\n",
        "    print(\"Current selected model: \", model_name)\n",
        "\n",
        "# Run chatbot\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Paim0n: Goodbye! \")\n",
        "        break\n",
        "\n",
        "    # Generate response\n",
        "    # response = chat.send_message(user_input)\n",
        "    # Use tavily search\n",
        "    tavily_result = tavily_search(user_input, )\n",
        "    print (tavily_result)\n",
        "    query = f\"\"\"\n",
        "    Below is some external information from web search about the question:\n",
        "    {tavily_result}\n",
        "\n",
        "    Use Gemini LLM with context-aware embeddings and external information to provide a detailed and accurate answer to the query:\n",
        "    \"{user_input}\"\n",
        "    \"\"\"\n",
        "    response = chat.send_message(query)\n",
        "    for chunk in response:\n",
        "        if chunk.text:\n",
        "          print(\"Paim0n: \", chunk.text)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}